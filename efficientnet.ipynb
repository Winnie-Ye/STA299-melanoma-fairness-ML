{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d17c83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c61503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b89ec84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_dataset = pd.read_csv(\"three_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d4c693f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skin_tone_category\n",
       "dark      233\n",
       "light     233\n",
       "medium    233\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_dataset[\"skin_tone_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f097704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_dataset_light = three_dataset[233:466]\n",
    "three_dataset_medium = three_dataset[466:699]\n",
    "three_dataset_dark = three_dataset[0:233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccc722ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6-7): 2 x MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9-10): 2 x MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12-14): 3 x MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c33a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),       # Resize to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],      # ImageNet means\n",
    "        std=[0.229, 0.224, 0.225]        # ImageNet stds\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94b83944",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'ddi + pad'\n",
    "img_files = [f for f in os.listdir(img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d24ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image):\n",
    "    original_size = image.size\n",
    "    target_size = (224, 224)\n",
    "    ratio = min(target_size[0] / original_size[0], target_size[1] / original_size[1])\n",
    "    new_size = (int(original_size[0] * ratio), int(original_size[1] * ratio))\n",
    "    resized_image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    new_image = Image.new(\"RGB\", target_size, (255, 255, 255))\n",
    "    paste_position = ((target_size[0] - new_size[0]) // 2, (target_size[1] - new_size[1]) // 2)\n",
    "    new_image.paste(resized_image, paste_position)\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab3340ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233, 150528)\n"
     ]
    }
   ],
   "source": [
    "folder = \"ddi + pad\"\n",
    "file_names = three_dataset_light[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    #print(image.size) # Returns (width, height)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_light = np.stack(images)\n",
    "print(X_light.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3cdfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_light = three_dataset_light[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_light_encoded = le.fit_transform(y_light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f1239e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['melanoma' 'not-melanoma']\n"
     ]
    }
   ],
   "source": [
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac70675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_light_train, X_light_test, y_light_train, y_light_test = train_test_split(X_light, y_light_encoded, test_size=0.2, stratify=y_light_encoded, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce874f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_train = pd.concat([three_dataset_light[three_dataset_light[\"label\"] == \"melanoma\"][:18],three_dataset_light[three_dataset_light[\"label\"] != \"melanoma\"][:168]], ignore_index=True)\n",
    "light_test = pd.concat([three_dataset_light[three_dataset_light[\"label\"] == \"melanoma\"][18:],three_dataset_light[three_dataset_light[\"label\"] != \"melanoma\"][168:]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "60fa5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"ddi + pad\"\n",
    "file_names = light_train[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    #print(image.size) # Returns (width, height)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_light_train = np.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4b44e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"ddi + pad\"\n",
    "file_names = light_test[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    #print(image.size) # Returns (width, height)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_light_test = np.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d687b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_light_train = light_train[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_light_train_encoded = le.fit_transform(y_light_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d920e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_light_test = light_test[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_light_test_encoded = le.fit_transform(y_light_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a6f07ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "not-melanoma    168\n",
       "melanoma         18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_light_train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4849c001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "not-melanoma    32\n",
       "melanoma        15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_light_test[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eff64b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_train = pd.concat([three_dataset_medium[three_dataset_medium[\"label\"] == \"melanoma\"][:23],three_dataset_medium[three_dataset_medium[\"label\"] != \"melanoma\"][:168]], ignore_index=True)\n",
    "medium_test = pd.concat([three_dataset_medium[three_dataset_medium[\"label\"] == \"melanoma\"][23:],three_dataset_medium[three_dataset_medium[\"label\"] != \"melanoma\"][168:]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7405974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"ddi + pad\"\n",
    "file_names = medium_train[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    #print(image.size) # Returns (width, height)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_medium_train = np.stack(images)\n",
    "\n",
    "folder = \"ddi + pad\"\n",
    "file_names = medium_test[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    #print(image.size) # Returns (width, height)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_medium_test = np.stack(images)\n",
    "\n",
    "y_medium_train = medium_train[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_medium_train_encoded = le.fit_transform(y_medium_train)\n",
    "\n",
    "y_medium_test = medium_test[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_medium_test_encoded = le.fit_transform(y_medium_test)\n",
    "\n",
    "X_medium_train_tensor = torch.tensor(X_medium_train, dtype=torch.float32)\n",
    "X_medium_test_tensor = torch.tensor(X_medium_test, dtype=torch.float32)\n",
    "y_medium_train_tensor = torch.tensor(y_medium_train_encoded, dtype=torch.long)\n",
    "y_medium_test_tensor = torch.tensor(y_medium_test_encoded, dtype=torch.long)\n",
    "\n",
    "X_medium_train_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\")) for img in X_medium_train])\n",
    "X_medium_test_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\")) for img in X_medium_test])\n",
    "\n",
    "train_medium_dataset = TensorDataset(X_medium_train_tensor, y_medium_train_tensor)\n",
    "test_medium_dataset = TensorDataset(X_medium_test_tensor, y_medium_test_tensor)\n",
    "\n",
    "train_medium_loader = DataLoader(train_medium_dataset, batch_size=32, shuffle=True)\n",
    "test_medium_loader = DataLoader(test_medium_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87788cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_train = pd.concat([three_dataset_dark[three_dataset_dark[\"label\"] == \"melanoma\"][:18],three_dataset_dark[three_dataset_dark[\"label\"] != \"melanoma\"][:168]], ignore_index=True)\n",
    "dark_test = pd.concat([three_dataset_dark[three_dataset_dark[\"label\"] == \"melanoma\"][18:],three_dataset_dark[three_dataset_dark[\"label\"] != \"melanoma\"][168:]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56168a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"ddi + pad\"\n",
    "file_names = dark_train[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    #print(image.size) # Returns (width, height)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_dark_train = np.stack(images)\n",
    "\n",
    "folder = \"ddi + pad\"\n",
    "file_names = dark_test[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    #print(image.size) # Returns (width, height)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_dark_test = np.stack(images)\n",
    "\n",
    "y_dark_train = dark_train[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_dark_train_encoded = le.fit_transform(y_dark_train)\n",
    "\n",
    "y_dark_test = dark_test[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_dark_test_encoded = le.fit_transform(y_dark_test)\n",
    "\n",
    "X_dark_train_tensor = torch.tensor(X_dark_train, dtype=torch.float32)\n",
    "X_dark_test_tensor = torch.tensor(X_dark_test, dtype=torch.float32)\n",
    "y_dark_train_tensor = torch.tensor(y_dark_train_encoded, dtype=torch.long)\n",
    "y_dark_test_tensor = torch.tensor(y_dark_test_encoded, dtype=torch.long)\n",
    "\n",
    "X_dark_train_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\")) for img in X_dark_train])\n",
    "X_dark_test_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\")) for img in X_dark_test])\n",
    "\n",
    "train_dark_dataset = TensorDataset(X_dark_train_tensor, y_dark_train_tensor)\n",
    "test_dark_dataset = TensorDataset(X_dark_test_tensor, y_dark_test_tensor)\n",
    "\n",
    "train_dark_loader = DataLoader(train_dark_dataset, batch_size=32, shuffle=True)\n",
    "test_dark_loader = DataLoader(test_dark_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b94e8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_light_train_tensor = torch.tensor(X_light_train, dtype=torch.float32)\n",
    "X_light_test_tensor = torch.tensor(X_light_test, dtype=torch.float32)\n",
    "y_light_train_tensor = torch.tensor(y_light_train_encoded, dtype=torch.long)\n",
    "y_light_test_tensor = torch.tensor(y_light_test_encoded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "aa3bd927",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_light_train_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\")) for img in X_light_train])\n",
    "X_light_test_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\")) for img in X_light_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9c1d4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_light_train_tensor, y_light_train_tensor)\n",
    "test_dataset = TensorDataset(X_light_test_tensor, y_light_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3522c265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/adae-py310/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/adae-py310/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.efficientnet_b0(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)  # 2 classes\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c629b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056ffe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 3.8021, Accuracy: 0.7204\n",
      "Epoch 2/10, Loss: 3.0424, Accuracy: 0.8602\n",
      "Epoch 3/10, Loss: 2.3581, Accuracy: 0.9355\n",
      "Epoch 4/10, Loss: 1.7895, Accuracy: 0.9785\n",
      "Epoch 5/10, Loss: 1.3360, Accuracy: 0.9624\n",
      "Epoch 6/10, Loss: 0.9876, Accuracy: 0.9785\n",
      "Epoch 7/10, Loss: 0.7328, Accuracy: 0.9839\n",
      "Epoch 8/10, Loss: 0.5919, Accuracy: 0.9785\n",
      "Epoch 9/10, Loss: 0.5132, Accuracy: 0.9839\n",
      "Epoch 10/10, Loss: 0.4341, Accuracy: 0.9946\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5b06b1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7234\n",
      "Confusion Matrix:\n",
      "[[ 2 13]\n",
      " [ 0 32]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Melanoma (0)       1.00      0.13      0.24        15\n",
      "  Benign (1)       0.71      1.00      0.83        32\n",
      "\n",
      "    accuracy                           0.72        47\n",
      "   macro avg       0.86      0.57      0.53        47\n",
      "weighted avg       0.80      0.72      0.64        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "test_accuracy = correct / len(test_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Melanoma (0)\", \"Benign (1)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ccc0a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"efficientnet_melanoma_light.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "656a9f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/adae-py310/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/adae-py310/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4.2103, Accuracy: 0.5753\n",
      "Epoch 2/10, Loss: 3.9344, Accuracy: 0.6398\n",
      "Epoch 3/10, Loss: 3.8387, Accuracy: 0.7473\n",
      "Epoch 4/10, Loss: 3.6421, Accuracy: 0.7849\n",
      "Epoch 5/10, Loss: 3.3445, Accuracy: 0.8118\n",
      "Epoch 6/10, Loss: 2.8894, Accuracy: 0.8817\n",
      "Epoch 7/10, Loss: 2.6972, Accuracy: 0.8817\n",
      "Epoch 8/10, Loss: 2.4286, Accuracy: 0.8871\n",
      "Epoch 9/10, Loss: 1.8792, Accuracy: 0.9355\n",
      "Epoch 10/10, Loss: 1.9636, Accuracy: 0.8978\n",
      "Test Accuracy: 0.8298\n",
      "Confusion Matrix:\n",
      "[[ 2  5]\n",
      " [ 3 37]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Melanoma (0)       0.40      0.29      0.33         7\n",
      "  Benign (1)       0.88      0.93      0.90        40\n",
      "\n",
      "    accuracy                           0.83        47\n",
      "   macro avg       0.64      0.61      0.62        47\n",
      "weighted avg       0.81      0.83      0.82        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# medium model\n",
    "folder = \"ddi + pad\"\n",
    "file_names = three_dataset_medium[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_medium = np.stack(images)\n",
    "#print(X_medium.shape)\n",
    "\n",
    "y_medium = three_dataset_medium[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_medium_encoded = le.fit_transform(y_medium)\n",
    "\n",
    "X_medium_train, X_medium_test, y_medium_train, y_medium_test = train_test_split(X_medium, y_medium_encoded, test_size=0.2, stratify=y_medium_encoded, random_state=42)\n",
    "\n",
    "X_medium_train_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\"))for img in X_medium_train])\n",
    "X_medium_test_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\"))for img in X_medium_test])\n",
    "y_medium_train_tensor = torch.tensor(y_medium_train, dtype=torch.long)\n",
    "y_medium_test_tensor = torch.tensor(y_medium_test, dtype=torch.long)\n",
    "\n",
    "train_dataset_medium = TensorDataset(X_medium_train_tensor, y_medium_train_tensor)\n",
    "test_dataset_medium = TensorDataset(X_medium_test_tensor, y_medium_test_tensor)\n",
    "train_loader_medium = DataLoader(train_dataset_medium, batch_size=32, shuffle=True)\n",
    "test_loader_medium = DataLoader(test_dataset_medium, batch_size=32)\n",
    "\n",
    "model_medium = models.efficientnet_b0(pretrained=True)\n",
    "model_medium.classifier[1] = nn.Linear(model_medium.classifier[1].in_features, 2)\n",
    "model_medium = model_medium.to(device)\n",
    "\n",
    "class_weights = [233 / 33, 233 / 200]\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "optimizer = optim.Adam(model_medium.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model_medium.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for images, labels in train_loader_medium:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_medium(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    accuracy = correct / len(train_dataset_medium)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "model_medium.eval()\n",
    "correct = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader_medium:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_medium(images)\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        correct += (preds == labels).sum().item()\n",
    "test_accuracy = correct / len(test_dataset_medium)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Melanoma (0)\", \"Benign (1)\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6e8923f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 1  6]\n",
      " [ 1 39]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Melanoma (0)       0.50      0.14      0.22         7\n",
      "  Benign (1)       0.87      0.97      0.92        40\n",
      "\n",
      "    accuracy                           0.85        47\n",
      "   macro avg       0.68      0.56      0.57        47\n",
      "weighted avg       0.81      0.85      0.81        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model_medium.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader_medium:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_medium(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Melanoma (0)\", \"Benign (1)\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "92411524",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_medium.state_dict(), \"efficientnet_melanoma_medium.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1b56951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/adae-py310/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/adae-py310/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 3.9566, Accuracy: 0.6022\n",
      "Epoch 2/10, Loss: 3.3506, Accuracy: 0.8226\n",
      "Epoch 3/10, Loss: 2.7409, Accuracy: 0.8925\n",
      "Epoch 4/10, Loss: 2.2982, Accuracy: 0.9140\n",
      "Epoch 5/10, Loss: 1.8200, Accuracy: 0.9409\n",
      "Epoch 6/10, Loss: 1.5030, Accuracy: 0.9677\n",
      "Epoch 7/10, Loss: 1.2972, Accuracy: 0.9624\n",
      "Epoch 8/10, Loss: 1.0870, Accuracy: 0.9677\n",
      "Epoch 9/10, Loss: 0.9223, Accuracy: 0.9677\n",
      "Epoch 10/10, Loss: 0.6797, Accuracy: 0.9839\n",
      "Test Accuracy: 0.8511\n"
     ]
    }
   ],
   "source": [
    "# dark model\n",
    "folder = \"ddi + pad\"\n",
    "file_names = three_dataset_dark[\"img_id\"]\n",
    "images = []\n",
    "\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_dark = np.stack(images)\n",
    "y_dark = three_dataset_dark[\"label\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_dark_encoded = le.fit_transform(y_dark)\n",
    "\n",
    "X_dark_train, X_dark_test, y_dark_train, y_dark_test = train_test_split(X_dark, y_dark_encoded, test_size=0.2, stratify=y_dark_encoded, random_state=42)\n",
    "\n",
    "X_dark_train_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\")) for img in X_dark_train])\n",
    "X_dark_test_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\")) for img in X_dark_test])\n",
    "\n",
    "y_dark_train_tensor = torch.tensor(y_dark_train, dtype=torch.long)\n",
    "y_dark_test_tensor = torch.tensor(y_dark_test, dtype=torch.long)\n",
    "\n",
    "train_dataset_dark = TensorDataset(X_dark_train_tensor, y_dark_train_tensor)\n",
    "test_dataset_dark = TensorDataset(X_dark_test_tensor, y_dark_test_tensor)\n",
    "\n",
    "train_loader_dark = DataLoader(train_dataset_dark, batch_size=32, shuffle=True)\n",
    "test_loader_dark = DataLoader(test_dataset_dark, batch_size=32)\n",
    "\n",
    "model_dark = models.efficientnet_b0(pretrained=True)\n",
    "model_dark.classifier[1] = nn.Linear(model_dark.classifier[1].in_features, 2)\n",
    "model_dark = model_dark.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_dark.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model_dark.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for images, labels in train_loader_dark:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_dark(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    accuracy = correct / len(train_dataset_dark)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "model_dark.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader_dark:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_dark(images)\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "test_accuracy = correct / len(test_dataset_dark)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e8766c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium test set size: 47\n",
      "Dark test set size: 47\n"
     ]
    }
   ],
   "source": [
    "print(\"Medium test set size:\", len(test_dataset_medium))\n",
    "print(\"Dark test set size:\", len(test_dataset_dark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "810bf663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples: 47\n",
      "Melanoma count (label=0): 7\n",
      "Benign count (label=1): 40\n"
     ]
    }
   ],
   "source": [
    "melanoma_count = np.sum(y_medium_test == 0)\n",
    "not_melanoma_count = np.sum(y_medium_test == 1)\n",
    "\n",
    "print(f\"Total test samples: {len(y_medium_test)}\")\n",
    "print(f\"Melanoma count (label=0): {melanoma_count}\")\n",
    "print(f\"Benign count (label=1): {not_melanoma_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "991ae5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_dark.state_dict(), \"efficientnet_melanoma_dark.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2613595a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/adae-py310/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/adae-py310/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 10.4098, Accuracy: 0.7621\n",
      "Epoch 2/10, Loss: 7.1601, Accuracy: 0.8623\n",
      "Epoch 3/10, Loss: 5.7421, Accuracy: 0.8748\n",
      "Epoch 4/10, Loss: 5.9962, Accuracy: 0.8694\n",
      "Epoch 5/10, Loss: 4.6274, Accuracy: 0.8980\n",
      "Epoch 6/10, Loss: 3.8475, Accuracy: 0.9141\n",
      "Epoch 7/10, Loss: 2.7587, Accuracy: 0.9517\n",
      "Epoch 8/10, Loss: 2.4011, Accuracy: 0.9606\n",
      "Epoch 9/10, Loss: 1.7025, Accuracy: 0.9857\n",
      "Epoch 10/10, Loss: 1.4212, Accuracy: 0.9911\n",
      "Test Accuracy: 0.8857\n"
     ]
    }
   ],
   "source": [
    "# total model\n",
    "folder = \"ddi + pad\"\n",
    "file_names = three_dataset[\"img_id\"]\n",
    "images = []\n",
    "\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_total = np.stack(images)\n",
    "y_total = three_dataset[\"label\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_total_encoded = le.fit_transform(y_total)\n",
    "\n",
    "X_total_train, X_total_test, y_total_train, y_total_test = train_test_split(X_total, y_total_encoded, test_size=0.2, stratify=y_total_encoded, random_state=42)\n",
    "\n",
    "X_total_train_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\")) for img in X_total_train])\n",
    "X_total_test_tensor = torch.stack([transform(Image.fromarray(img.astype('uint8')).convert(\"RGB\")) for img in X_total_test])\n",
    "\n",
    "y_total_train_tensor = torch.tensor(y_total_train, dtype=torch.long)\n",
    "y_total_test_tensor = torch.tensor(y_total_test, dtype=torch.long)\n",
    "\n",
    "train_dataset_total = TensorDataset(X_total_train_tensor, y_total_train_tensor)\n",
    "test_dataset_total = TensorDataset(X_total_test_tensor, y_total_test_tensor)\n",
    "\n",
    "train_loader_total = DataLoader(train_dataset_total, batch_size=32, shuffle=True)\n",
    "test_loader_total = DataLoader(test_dataset_total, batch_size=32)\n",
    "\n",
    "model_total = models.efficientnet_b0(pretrained=True)\n",
    "model_total.classifier[1] = nn.Linear(model_total.classifier[1].in_features, 2)\n",
    "model_total = model_total.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_total.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model_total.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for images, labels in train_loader_total:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_total(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    accuracy = correct / len(train_dataset_total)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "model_total.eval()\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader_total:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_total(images)\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "test_accuracy = correct / len(test_dataset_total)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0000141",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_total.state_dict(), \"efficientnet_melanoma_total.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4a51992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qz/3gzbdppx7f3fd_hs65_qss5c0000gn/T/ipykernel_9662/318641267.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_light.load_state_dict(torch.load(\"efficientnet_melanoma_light.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_light = models.efficientnet_b0(pretrained=False)\n",
    "model_light.classifier[1] = nn.Linear(model_light.classifier[1].in_features, 2)\n",
    "model_light.load_state_dict(torch.load(\"efficientnet_melanoma_light.pth\"))\n",
    "model_light = model.to(device)\n",
    "model_light.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83796080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# medium set\n",
    "folder = \"ddi + pad\"\n",
    "file_names = three_dataset_medium[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    #print(image.size) # Returns (width, height)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_medium = np.stack(images)\n",
    "#print(X_medium.shape)\n",
    "\n",
    "y_medium = three_dataset_medium[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_medium_encoded = le.fit_transform(y_medium)\n",
    "\n",
    "X_medium_tensor = torch.stack([transform(Image.fromarray(img.astype(\"uint8\")).convert(\"RGB\"))for img in X_medium])\n",
    "y_medium_tensor = torch.tensor(y_medium_encoded, dtype=torch.long)\n",
    "\n",
    "test_dataset_medium = TensorDataset(X_medium_tensor, y_medium_tensor)\n",
    "test_loader_medium = DataLoader(test_dataset_medium, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5caf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on medium skin tone: 0.7039\n"
     ]
    }
   ],
   "source": [
    "# test medium set in light model\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader_medium:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "accuracy_medium = correct / len(test_dataset_medium)\n",
    "print(f\"Test Accuracy on medium skin tone: {accuracy_medium:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d92c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dark set\n",
    "folder = \"ddi + pad\"\n",
    "file_names = three_dataset_dark[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    #print(image.size) # Returns (width, height)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_dark = np.stack(images)\n",
    "#print(X_dark.shape)\n",
    "\n",
    "y_dark = three_dataset_dark[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_dark_encoded = le.fit_transform(y_dark)\n",
    "\n",
    "X_dark_tensor = torch.stack([\n",
    "    transform(Image.fromarray(img.astype(\"uint8\")).convert(\"RGB\")) \n",
    "    for img in X_dark\n",
    "])\n",
    "y_dark_tensor = torch.tensor(y_dark_encoded, dtype=torch.long)\n",
    "\n",
    "test_dataset_dark = TensorDataset(X_dark_tensor, y_dark_tensor)\n",
    "test_loader_dark = DataLoader(test_dataset_dark, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef74edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on dark skin tone: 0.6910\n"
     ]
    }
   ],
   "source": [
    "# test dark set in light model\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader_dark:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "accuracy_dark = correct / len(test_dataset_dark)\n",
    "print(f\"Test Accuracy on dark skin tone: {accuracy_dark:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd65ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# light set\n",
    "folder = \"ddi + pad\"\n",
    "file_names = three_dataset_light[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    images.append(np.array(image_resize(image)).flatten())\n",
    "X_light = np.stack(images)\n",
    "\n",
    "y_light = three_dataset_light[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_light_encoded = le.fit_transform(y_light)\n",
    "\n",
    "X_light_tensor = torch.stack([transform(Image.fromarray(img.astype(\"uint8\")).convert(\"RGB\"))for img in X_medium])\n",
    "y_light_tensor = torch.tensor(y_light_encoded, dtype=torch.long)\n",
    "\n",
    "test_dataset_light = TensorDataset(X_light_tensor, y_light_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10d2fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# light + medium + dark set\n",
    "folder = \"ddi + pad\"\n",
    "file_names = three_dataset[\"img_id\"]\n",
    "images = []\n",
    "for file in file_names:\n",
    "    path = os.path.join(folder, file)\n",
    "    image = PIL.Image.open(path)\n",
    "    images.append(np.array(image_resize(image)))\n",
    "X_total = np.stack(images)\n",
    "\n",
    "y_total = three_dataset[\"label\"]\n",
    "le = LabelEncoder()\n",
    "y_total_encoded = le.fit_transform(y_total)\n",
    "\n",
    "X_total_tensor = torch.stack([transform(Image.fromarray(img.astype(\"uint8\")).convert(\"RGB\"))for img in X_total])\n",
    "y_total_tensor = torch.tensor(y_total_encoded, dtype=torch.long)\n",
    "\n",
    "test_dataset_total = TensorDataset(X_total_tensor, y_total_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0653c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adae-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
